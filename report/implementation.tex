\chapter{Implementation}

\section{Design Decisions}

To select a programming language suitable for developing the tool, languages were compared with respect to possible challenges. The language should be compatible with popular optimisation solvers. To make efficient use of time, using an existing interface library between popular solvers is recommended. Interfaces are written for popular languages such as C++, Java and Python. Python was selected for its development speed and support for a wide range of libraries.
\linespace
There is a balance between program speed and development time. A tool written in C may be fast but time-consuming. The purpose is to demonstrate the concept of argumentation with schedules while allowing analysis of potential future directions and short-comings. Hence, the tool should be sufficiently fast to be responsive, but not necessarily fast as possible.
\linespace
There are many powerful and efficient solvers such as CPLEX [paper] and GLPK [paper]. To solver large problems, users use commercial over open-source solvers for their superior speed [paper]. However, users may not have access to a commercial solver. To accommodate users, Pyomo is used to interface to many popular solvers.
\linespace
The tool features a GUI to aid its accessibility. Users such as hospital managers can often use a suitably-designed GUI without training of the tool. In practice, a GUI is easier to demonstrate than a CLI.

\section{Structure}

\begin{figure}[H]
	\resizebox{\textwidth}{!}{
	\begin{tikzpicture}
		\fill[fill=black!10](-1.7, -0.8) rectangle (11.2, 3);
		\node at (3, 0){External libraries};
		
		\node[file](numpy) at (0, 0){NumPy};
		\node[file](cplex) at (6, 0){CPLEX};
		\node[file](glpk) at (10, 0){GLPK};
		\node[file](matplotlib) at (0, 2){Matplotlib};
		\node[file](tkinter) at (4, 2){Tkinter};		
		\node[file](pyomo) at (8, 2){Pyomo};
		\node[file](visualise) at (0, 4){\texttt{visualise.py}};
		\node[file](graphical) at (4, 4){\texttt{graphical.py}};
		\node[file](solver) at (8, 4){\texttt{solver.py}};
		\node[file](schedule) at (0, 6){\texttt{schedule.py}};
		\node[file](argumentation) at (0, 8){\texttt{argumentation.py}};
		\node[file](interface) at (4, 8){\texttt{interface.py}};
		\node[file](main) at (4, 10){\texttt{main.py}};
		\draw[arrow, dashed](cplex) -- (pyomo);
		\draw[arrow, dashed](glpk) -- (pyomo);
		\draw[arrow](numpy) -- (matplotlib);
		\draw[arrow](matplotlib) -- (visualise);
		\draw[arrow](visualise) -- (schedule);
		\draw[arrow](pyomo) -- (solver);
		\draw[arrow](tkinter) -- (graphical);
		\draw[arrow](visualise) -- (graphical);
		\draw[arrow](graphical) -- (interface);
		\draw[arrow](solver) -- (interface);
		\draw[arrow](argumentation) -- (interface);
		\draw[arrow](schedule) -- (interface);
		\draw[arrow](schedule) -- (argumentation);
		\draw[arrow](interface) -- (main);
	\end{tikzpicture}}

	\caption{The graph illustrates the functional dependency between modules in the code-base of the tool. A solver is required for full functionality of the tool. This could be CPLEX or GLPK.}
\end{figure}


\section{Algorithms}

\subsection{Notation}

The algorithm uses operators over boolean tensors to generate frameworks and compute stability. The definitions below share notions with linear algebra over matrices.

\begin{definition}
	Let $\mathbf{0}^{d_1, ..., d_n}$ be the zero-valued boolean tensor. The dimensions may be omitted if clear. Matrix subscripts are extended to $n$ dimensions.
		
	For example:
	\begin{align*}
	\mathbf{0}^{2\times 2}&=
	\begin{bmatrix}
	0&0\\
	0&0\\
	\end{bmatrix}
	\end{align*}
\end{definition}

\begin{definition}
	Let $\incircbin{\neg}$ be the element-wise logical negation operator over a tensor.
	
	For example:
	\begin{align*}
		\incircbin{\neg}
		\begin{bmatrix}
		1&0\\
		0&1\\
		\end{bmatrix}&=
		\begin{bmatrix}
			0&1\\
			1&0\\
		\end{bmatrix}
	\end{align*}
\end{definition}

\begin{definition}
	Let $\incircbin{\land}$ be the element-wise logical and operator over tensors.
	
	For example:
	\begin{align*}
	\begin{bmatrix}
	0&0\\
	1&1\\
	\end{bmatrix}
	\incircbin{\land}
	\begin{bmatrix}
	0&1\\
	0&1\\
	\end{bmatrix}
	&=
	\begin{bmatrix}
	0&0\\
	0&1\\
	\end{bmatrix}
	\end{align*}
\end{definition}

\begin{definition}
	Let $\incircbin{\lor}$ be the element-wise logical or operator over tensors.
	
	For example:
	\begin{align*}
	\begin{bmatrix}
	0&0\\
	1&1\\
	\end{bmatrix}
	\incircbin{\lor}
	\begin{bmatrix}
	0&1\\
	0&1\\
	\end{bmatrix}
	&=
	\begin{bmatrix}
	0&1\\
	1&1\\
	\end{bmatrix}
	\end{align*}
\end{definition}

\subsection{Summary}

\begin{figure}[H]
	\resizebox{\textwidth}{!}{
	\begin{tikzpicture}
		\node[node](start) at (0, 12){Start};
		\node[file, align=center](fpe) at (0, 6){
			\textsc{Full-Precomputation-Explain}
			\\\\
			\tikz{
				\node[file](cf) at (2.5, 8){\textsc{Construct-}\\\textsc{Feasibility}};
				\node[file](ce) at (4, 6){\textsc{Construct-}\\\textsc{Efficiency}};
				\node[file](cs) at (8, 6){\textsc{Construct-}\\\textsc{Satisfaction}};
				\node[file](sf) at (0, 4){\textsc{Explain-}\\\textsc{Stability}};
				\node[file](se) at (4, 4){\textsc{Explain-}\\\textsc{Stability}};
				\node[file](ss) at (8, 4){\textsc{Explain-}\\\textsc{Stability}};
				\node[file](ef) at (0, 2){\textsc{Explain-}\\\textsc{Feasibility}};
				\node[file](ee) at (4, 2){\textsc{Explain-}\\\textsc{Efficiency}};
				\node[file](es) at (8, 2){\textsc{Explain-}\\\textsc{Satisfaction}};
				\draw[arrow](cf) -- (sf);
				\draw[arrow](cf) -- (ce);
				\draw[arrow](cf) -- (cs);
				\draw[arrow](ce) -- (se);
				\draw[arrow](cs) -- (ss);
				\draw[arrow](sf) -- (ef);
				\draw[arrow](se) -- (ee);
				\draw[arrow](ss) -- (es);
			};
		};
		\node[node](end) at (0, 0){End};
		\draw[arrow](start) -- (fpe);
		\draw[arrow](fpe) -- (end);
	\end{tikzpicture}}
	\caption{The graph summaries the required execution order of sub-functions in the \textsc{Full-Precomputation-Explain} algorithm. Nested rectangles denote nested function calls.}
\end{figure}

\begin{figure}[H]
	\resizebox{\textwidth}{!}{
		\begin{tikzpicture}
		\node[node](start) at (0, 24) {Start};
		\node[file, align=center](fpe) at (0, 12){
			\textsc{Partial-Precomputation-Explain}
			\\\\
			\tikz{
				\node[file](cf) at (2.5, 14){
					\textsc{Compute-}\\\textsc{Unattacked}
					\\\\
					\tikz{
						\node[file]{\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Feasibility}};
					}
				};
				\node[file](ce) at (5, 9){
					\textsc{Compute-}\\\textsc{Unattacked}
					\\\\
					\tikz{
						\node[file]{\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Efficiency}};
					}
				};
				\node[file](cs) at (10, 9){
					\textsc{Compute-}\\\textsc{Unattacked}
					\\\\
					\tikz{
						\node[file]{\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Satisfaction}};
					}
				};
				\node[file](sf) at (0, 3.5){
					\textsc{Explain-}\\\textsc{Feasibility}
					\\\\
					\tikz{
						\node[file]{
							\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Conflicts}
							\\\\
							\tikz{
								\node[file]{
									\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Feasibility}
								};
							}
						};
					}
				};
				\node[file](se) at (5, 1){
					\textsc{Explain-}\\\textsc{Efficiency}
					\\\\
					\tikz{
						\node[file](ccf) at (0, 5){
							\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Conflicts}
							\\\\
							\tikz{
								\node[file]{
									\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Feasibility}
								};
							}
						};
						\node[file](cce) at (0, 0){
							\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Conflicts}
							\\\\
							\tikz{
								\node[file]{
									\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Efficiency}
								};
							}
						};
						\draw[arrow](ccf) -- (cce);
					}
				};
				\node[file](ss) at (10, 1){
					\textsc{Explain-}\\\textsc{Satisfaction}
					\\\\
					\tikz{
						\node[file](ccf) at (0, 5){
							\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Conflicts}
							\\\\
							\tikz{
								\node[file]{
									\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Feasibility}
								};
							}
						};
						\node[file](ccs) at (0, 0){
							\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Conflicts}
							\\\\
							\tikz{
								\node[file]{
									\textsc{Compute-}\\\textsc{Partial-}\\\textsc{Satisfaction}
								};
							}
						};
						\draw[arrow](ccf) -- (ccs);
					}
				};
				\draw[arrow](cf) -- (sf);
				\draw[arrow](cf) -- (ce);
				\draw[arrow](cf) -- (cs);
				\draw[arrow](ce) -- (se);
				\draw[arrow](cs) -- (ss);
			};
		};
		\node[node](end) at (0, 0){End};
		\draw[arrow](start) -- (fpe);
		\draw[arrow](fpe) -- (end);
		\end{tikzpicture}}
	\caption{The graph summaries the required execution order of sub-functions in the \textsc{Partial-Precomputation-Explain} algorithm.}
\end{figure}

\subsection{Framework Construction}

The AAFs are constructed using the definitions in paper \cite{aes}. The definitions are reprinted for feasibility and fixed decisions only. Take arbitrary $i_1,i_2\in\mathcal{M}$ and $j_1,j_2\in\mathcal{J}$.

\begin{definition}
	The feasibility framework $\rightsquigarrow_F$ is defined such that $\langle i_1,j_1\rangle\rightsquigarrow_F\langle i_2,j_2\rangle$ iff $i_1\neq i_2\land j_1=j_2$.
\end{definition}

\begin{definition}
	The efficiency framework $\rightsquigarrow_S$ is defined such that $\langle i_1,j_1\rangle\rightsquigarrow_S\langle i_2,j_2\rangle\land\neg\text{SEP}(i_1,i_2,j_1)\lor\text{PEP}(i_1,i_2,j_1,j_2)$ where:
	\begin{itemize}
		\item Single exchange property (SEP): $\text{SEP}(i_1,i_2,j_1, D)$ iff $C_{i_1}=C_{\max}\land x_{i_1,j_1}=1\land C_{i_1}>C_{i_2}+p_{j_1}$
		\item Pair-wise exchange property (PEP): $\text{PEP}(i_1,i_2,j_1,j_2, D)$ iff $C_{i_1}=C_{\max}\land x_{i_1,j_1}=1\land x_{i_2,j_2}=1\land i_1\neq i_2\land j_1\neq j_2\land p_{j_1}>p_{j_2}\land C_{i_1}+p_{j_2}>C_{i_2}+p_{j_1}$.
	\end{itemize}

	The paper \cite{aes} defines $\rightsquigarrow_S$ as an optimality framework. This report refers to $\rightsquigarrow_S$ as an efficiency framework, as its stability is determined by necessary but not sufficient conditions for optimality. In addition, the paper does considers efficiency and satisfaction to fixed decisions seperately, we extend the notion of efficiency to respect these decisions. With the paper's definition of efficiency, the tool would recommend exchanges which violate fixed decisions.
\end{definition}

\begin{definition}
	The fixed user decision framework $\rightsquigarrow_D$ is defined such that $\langle i_1,j_1\rangle\rightsquigarrow_S\langle i_2,j_2\rangle\land\neg\text{DP}^+(i_1,i_2,j_1,j_2)\lor\text{DP}^-(i_1,i_2,j_1,j_2)$ where:
	\begin{itemize}
		\item Positive decision property: $\text{DP}^+(i_1,i_2,j_1,j_2)$ iff $\langle i_2, j_2\rangle\in D^+$
		\item Negative decision property: $\text{DP}^-(i_1,i_2,j_1,j_2)$ iff $\langle i_1, j_1\rangle\in D^-\land i_1=i_2\land j_1=j_2$.
	\end{itemize}
\end{definition}

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Construct-Feasibility}{$m$, $n$}
			\State $\rightsquigarrow_F$ $\gets$ $\mathbf{0}^{(m\times n)^2}$
			\For{$j\in\mathcal{J}$}
				\For{$i_1\in\mathcal{M}$}
					\For{$i_2\in\mathcal{M}$}
						\If{$i_1\neq i_2$}
							\State ${\rightsquigarrow_F}_{i_1,j,i_2,j}$ $\gets$ 1
						\EndIf
					\EndFor
				\EndFor
			\EndFor
			\State \Return $\rightsquigarrow_F$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

$\rightsquigarrow_F$ can be constructed trivially in a dense data structure in $\mathcal{O}(m^2n^2)$ computational complexity, because of the complexity of zero-initialising $\rightsquigarrow_F$. This can be constructed in $\mathcal{O}(m^2n)$ complexity using a sparse data structure, but results in greatly more complicated code.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Construct-Efficiency}{$m$, $n$, $\mathbf{p}$, $\mathbf{x}$, $D$, $\rightsquigarrow_F$}
			\State $\mathbf{C}$ $\gets$ $\mathbf{x}\cdot\mathbf{p}$
			\State $C_{\max}$ $\gets$ $\max(\mathbf{C})$
			\State $\rightsquigarrow_S$ $\gets$ $\rightsquigarrow_F$
			\For{$i_1\in\mathcal{M}$}
				\If{$i_1=C_{\max}$}
					\For{$j_1\in\mathcal{J}$}
						\If{$x_{i_1,j_1}=1$}
							\For{$i_2\in\mathcal{M}$}
								\If{$\text{SEP}(i_1,j_1,i_2)$}
									\State ${\rightsquigarrow_S}_{i_1,j_1,i_2,j_1}$ $\gets$ 0
								\EndIf
								\For{$j_2\in\mathcal{J}$}
									\If{$\text{PEP}(i_1,j_1,i_2,j_2)$}
										\State ${\rightsquigarrow_S}_{i_1,j_2,i_2,j_2}$ $\gets$ 1
									\EndIf
								\EndFor
							\EndFor
						\EndIf
					\EndFor
				\EndIf
			\EndFor
			\State \Return $\pair{\rightsquigarrow_S}{\mathbf{C}}$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The construction of $\rightsquigarrow_S$ is expensive because of the explicit for-loops to iterate over the $\mathcal{M}^2\mathcal{J}^2$ space to compute the edges that satisfy PEP and to copy $\rightsquigarrow_F$. An optimisation by computing SEP outside of the $j_2$ loop, because PEP is invariant of $j_2$. We return the value of $\mathbf{C}$ because it will be used later, rather an recompute its value when necessary

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Construct-Satisfaction}{$m$, $n$, $D$, $\rightsquigarrow_F$}
			\State $\rightsquigarrow_D$ $\gets$ $\rightsquigarrow_F$
			\For{$\langle i,j\rangle\in D^-$}
				\State ${\rightsquigarrow_S}_{i,j,i,j}$ $\gets$ 1
			\EndFor
			\For{$\langle i_1,j_1\rangle\in D^+$}
				\For{$i_2\in\mathcal{M}$}
					\For{$j_2\in\mathcal{J}$}
						\State ${\rightsquigarrow_D}_{i_2,j_2,i_1,j_1}$ $\gets$ 0				
					\EndFor
				\EndFor
			\EndFor
			\State \Return $\rightsquigarrow_D$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

If $D$ is assumed to be satisfiable, then $D^+$ has at most $n$ decisions while $D^-$ has at most $(m-1)n$ decisions. However, if $D$ is not necessarily satisfiable to account for poorly-formulated user problems, so in general $D^+$ and $D^-$ has at most $mn$ decisions.

\subsection{Stability}

Stability can be computed by checking whether $E$ exists within a all possible stable extensions of some $\langle Args, \rightsquigarrow\rangle$. However, a schedule cannot be reasoned on without understanding whether $E$ may be stable on $\langle Args, \rightsquigarrow\rangle$. Existing solutions require a complication pipeline using answer set solvers. To make the implementation of the tool easier, we adapt the stability computation to schedules into a concise algorithm.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Explain-Stability}{$\mathbf{x}$, $\rightsquigarrow$, $\bar{\mathbf{u}}$, $\bar{\mathbf{c}}$}
			\State $\mathbf{u}$ $\gets$ \textsc{Compute-Unattacked}($\mathbf{x}$, $\rightsquigarrow$, $\bar{\mathbf{u}}$)
			\For{$i\in\mathcal{M}$}
				\For{$j\in\mathcal{J}$}
					\State $c_{i,j}$ $\gets$ \textsc{Compute-Partial-Conflicts}($\mathbf{x}$, $\rightsquigarrow_{i,j}$, $\bar{c}_{i,j}$)
				\EndFor
			\EndFor			
			\State \Return $\pair{\mathbf{u}}{\mathbf{c}}$
		\EndFunction
		\Function{Compute-Unattacked}{$\mathbf{x}$, $\rightsquigarrow$, $\bar{\mathbf{u}}$}
			\State $\mathbf{u}$ $\gets\incircbin{\neg}$ $\mathbf{x}$
			\For{$i\in\mathcal{M}$}
				\For{$j\in\mathcal{J}$}
					\If{$x_{i,j}=1$}
						\State $\mathbf{u}$ $\gets$ $\mathbf{u}$ $\incircbin{\land}$ $\incircbin{\neg}\rightsquigarrow_{i,j}$
					\EndIf
				\EndFor
			\EndFor
			\State $\mathbf{u}$ $\gets$ $\mathbf{u}$ $\incircbin{\land}$ $\incircbin{\neg}$ $\bar{\mathbf{u}}$
			\State \Return $\mathbf{u}$
		\EndFunction
		\Function{Compute-Partial-Conflicts}{$\mathbf{x}$, $\rightsquigarrow_{i, j}$, $\bar{c}_{i,j}$}
			\State $c_{i,j}$ $\gets\mathbf{0}^{m\times n}$
			\If{$x_{i,j}=1$}
				\State $c_{i,j}$ $\gets$ $\mathbf{x}$ $\incircbin{\land}$ $\rightsquigarrow_{i,j}$ 
			\EndIf
			\State $c_{i,j}$ $\gets$ $c_{i,j}$ $\incircbin{\land}$ $\incircbin{\neg}$ $\bar{c}_{i,j}$
			\State \Return $c_{i,j}$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The function \textsc{Explain-Stability} returns two tensors, $\mathbf{u}$ encode the unattacked nodes and $\mathbf{c}$ encode the edges are not conflict-free. $\bar{\mathbf{u}}$ and $\bar{\mathbf{c}}$ represent node and edges to ignore from returned values respectively, which are useful in tailoring explanations to particular constraints. By default, $\bar{\mathbf{u}}$ $=\mathbf{0}$ and $\bar{\mathbf{c}}$ $=\mathbf{0}$. The function uses $\mathbf{x}$ rather than its equivalent representation $E$ because $\mathbf{x}$ can be manipulated directly from an optimiser in its tensor form unlike $E$. This results in improved performance. In addition, it is assumed that $E\subseteq Args$ so $Args$ does not need to be a parameter.
\linespace
The auxiliary functions \textsc{Compute-Unattacked} and \textsc{Compute-Partial-Conflicts} are defined such that at most $\mathcal{O}(mn)$ memory is allocated. This will be discussed in the following subsections.

\begin{theorem}
	\textsc{Compute-Conflicts} is correct where $\mathbf{x}\approx E$ under $S$:
	\begin{align*}
	\textsc{Compute-Conflicts}(\mathbf{x},\rightsquigarrow,\mathbf{0})=\mathbf{0}\Leftrightarrow E\text{ is conflict-free on }\langle Args, \rightsquigarrow\rangle
	\end{align*}
\end{theorem}

\begin{theorem}
	\textsc{Explain-Stability} is correct where $\mathbf{x}\approx E$ under $S$:
	\begin{align*}
		\textsc{Explain-Stability}(\mathbf{x},\rightsquigarrow,\mathbf{0},\mathbf{0})=\pair{\mathbf{0}}{\mathbf{0}}\Leftrightarrow E\text{ is stable on }\langle Args, \rightsquigarrow\rangle
	\end{align*}
\end{theorem}
	
\subsection{Explanation}

Explanations are given in italics. Implementation of algorithms use Python's \verb|print()| to collect explanations over all algorithms in the tool's output.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Explain-Feasibility}{$\mathbf{u}$, $\mathbf{c}$}
			\If{$m=0$}
				\If{$n=0$}
					\State \emph{There are no jobs, so the schedule is trivially feasible.}
				\Else
					\State \emph{There are no machines to allocate to jobs.}
				\EndIf
			\Else
				\State $\mathbf{y}$ $\gets$ $\mathbf{0}^n$
				\State $\mathbf{z}$ $\gets$ $\mathbf{0}^{n\times m}$
				\For{$j\in\mathcal{J}$}
					\For{$i_1\in\mathcal{M}$}
						\For{$i_2\in\mathcal{M}$}
							\If{$c_{i_1,j,i_2,j}=1$}
								\State $y_j$ $\gets$ $1$
								\State $z_{j,i_1}$ $\gets$ $1$
								\State $z_{j,j_2}$ $\gets$ $1$
							\EndIf
						\EndFor
					\EndFor					
				\EndFor
				\If{$u^T_0=\mathbf{0}\land\mathbf{y}=\mathbf{0}$}
					\State \emph{All jobs are allocated by exactly one machine.}
				\Else
					\For{$j\in\mathcal{J}$}
						\If{$u_{0,j}=1$}
							\State \emph{Job $j$ is not allocated by any machine.}
						\EndIf
						\If{$y_j\neq\mathbf{0}$}
							\State \emph{Job $j$ is over-allocated by machines $\{i\ |\ i\in\mathcal{M}, z_{j,i}=1\}$.}
						\EndIf
					\EndFor
				\EndIf
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The paper \cite{aes} does not state explanations for trivial cases when $m=0$ or $n=0$. The above algorithm handles these cases with additional explanations. A problem with the naive implementation of generating an explanation for each conflict in $\mathbf{c_F}$ results in $k^2$ explanations for $k$ conflicting machines for a job. This results in superfluous text for the user. To summarise these explanations, the algorithm constructs a pseudo-schedule $\mathbf{z}$ which can be interpreted as $\mathbf{x}$ transposed and rows filtered if $\sum_{i\in\mathcal{M}}x_{i,j}>1$ for all jobs $j$. Afterwards, the algorithm prints the non-zero indices of $\mathbf{c}'$, which refer to the machines that causes over-allocation.

The algorithm features two optimisations. The variable $\mathbf{y}$ represent over-allocated jobs. $y_j=\mathbf{0}$ is faster to compute than its equivalent $z_j=\mathbf{0}$ because $y_j$ is an scalar aggregate over conflicting machines, unlike the vector $z_j$. Likewise, by the construction of $\mathbf{u_F}$, we can exploit $u^T_0=\mathbf{0}\iff\mathbf{u}=\mathbf{0}$ because $u^T_0=\frac{1}{m}\mathbf{u}^T\cdot\mathbf{1}^m$.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Explain-Efficiency}{$\mathbf{p}$, $\mathbf{C}$, $\mathbf{u}$, $\mathbf{c}$}				\State $i_1$ $\gets$ first argmax of $\mathbf{C}$
			\State reasons $\gets$ empty list
			\For{$j_1\in\mathcal{J}$}
				\For{$i_2\in\mathcal{M}$}
					\If{$u_{i_2,j_1}=1$}
						\State reason $\gets$ \emph{Job $j_1$ can be allocated to machine $i_2$.}
						\State append reason to reasons
					\EndIf
					\For{$j_2\in\mathcal{J}$}
						\If{$c_{i_1,j_1,i_2,j_2}=1$}
							\State reason $\gets$ \emph{Job $j_1$ and $j_2$ can be swapped with machines $i_1$ and $i_2$.}
							\State append reason to reasons
						\EndIf
					\EndFor
				\EndFor
			\EndFor
			\State sort reasons by $\langle$reduction, processing time$\rangle$
			\If{reasons is empty}
				\State\emph{All jobs satisfy single and pairwise exchange properties.}
			\Else
				\State output reasons
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The algorithm has $\mathcal{O}(mn^2\log(mn))$ computational complexity, arising from sorting reasons generated. Explanation of efficiency results in at most $m^2n^2$ lines, which  grows quickly for large schedules. To make this easier for the user to understand, we sort the explanations by its reduction, the amount the total completion time will reduce when an  single or pairwise exchange occurs. This will highlight the most significant improvements for the user. This justifies the increased complexity with the logarithmic factor.
\linespace
A key limitation with sorting by reduction, is in the cases of multiple critical machines. In this case, all reductions are zero. This is because single or pairwise exchange results in local optimisations of the same objective value. To find a strictly more optimal schedule, we need to look $k$ steps ahead, where $k$ is the number of critical machines. To solve this, the tool will need to generate instructions of $k$ actions, of single and pair-wise exchanges. For an arbitrary large schedule, this will cause an exponential explosion in $k$ of the explanation length. We continue the assumption that exponential tractable complexity is not feasible, so therefore, a full explanation for efficiency is not feasible.
\linespace
An alternative solution is to restrict the explanation space by giving local explanations. Hence in the algorithm, we consider only one critical machine. This reduces the computational complexity by a factor of $m$, which is significant because efficiency is the most expensive schedule property to explain.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Explain-Satisfaction}{$D$, $\mathbf{u}$, $\mathbf{c}$}
			\For{$j\in\mathcal{J}$}
				\If{$\exists i\in\mathcal{M}.\ \pair{i}{j}\not\in D^-$}
					\State\emph{Job $j$ cannot be allocated to any machine.}
				\EndIf
				\If{$D^-$ and $D^+$ are not disjoint}
					\State\emph{Job $j$ subject to conflicting negative and positive fixed user decisions.}
				\EndIf
				\If{$|i\in\mathcal{M},\pair{i}{j}\in D^+|>1$}
					\State\emph{Job $j$ cannot be allocated to multiple machines.}	
				\EndIf
			\EndFor
			\State $\mathbf{y}$ $\gets$ $\mathbf{0}^{m\times n}$
			\For{$i\in\mathcal{M}$}
				\For{$j\in\mathcal{J}$}
					\State $\mathbf{y}$ $\gets$ $\mathbf{y}$ $\incircbin{\lor}$ $c_{i,j}$
				\EndFor
			\EndFor
			\If{$\mathbf{u}=\mathbf{0}\land\mathbf{y}=\mathbf{0}$}
				\State\emph{All jobs satisfy user fixed decisions.}
			\Else
				\For{$i\in\mathcal{M}$}
					\For{$j\in\mathcal{J}$}
						\If{$u_{i,j}$}
							\State\emph{Job $j$ must be allocated to machine $i$.}
						\EndIf
						\If{$y_{i,j}$}
							\State\emph{Job $j$ must not be allocated to machine $i$.}
						\EndIf			
					\EndFor
				\EndFor
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The variable $\mathbf{y}$ refers to allocations not satisfying $D^+$. Because of the relaxation that $D$ is not assumed to be satisfiable, we must check the sufficient conditions for this, and generate their explanations if necessary.

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Full-Precomputation-Explain}{$m$, $n$, $\mathbf{p}$, $D$, $\mathbf{x}$}
			\State $\rightsquigarrow_F$ $\gets$ \textsc{Construct-Feasibility}($m$, $n$)
			\State $\pair{\mathbf{u_F}}{\mathbf{c_F}}$ $\gets$ \textsc{Explain-Stability}($\mathbf{x}$, $\rightsquigarrow_F$, $\mathbf{0}$, $\mathbf{0}$)
			\State\textsc{Explain-Feasibility}($\mathbf{u_F}$, $\mathbf{c_F}$)

			\State $\pair{\rightsquigarrow_S}{\mathbf{C}}$ $\gets$ \textsc{Construct-Efficiency}($m$, $n$, $\mathbf{p}$, $\mathbf{x}$, $D$, $\rightsquigarrow_F$)
			\State $\pair{\mathbf{u_S}}{\mathbf{c_S}}$ $\gets$ \textsc{Explain-Stability}($\mathbf{x}$, $\rightsquigarrow_S$, $\mathbf{u_F}$, $\mathbf{c_F}$)
			\State\textsc{Explain-Efficiency}($\mathbf{p}$, $\mathbf{C}$, $\mathbf{u_S}$, $\mathbf{c_S}$)

			\State $\rightsquigarrow_D$ $\gets$ \textsc{Construct-Satisfaction}($m$, $n$, $\mathbf{x}$, $\rightsquigarrow_F$)
			\State $\pair{\mathbf{u_D}}{\mathbf{c_D}}$ $\gets$ \textsc{Explain-Stability}($\mathbf{x}$, $\rightsquigarrow_D$, $\mathbf{u_F}$, $\mathbf{c_F}$)
			\State\textsc{Explain-Satisfaction}($\mathbf{u_D}$, $\mathbf{c_D}$)
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The above high-level algorithm generates explanations for feasibility, efficiency and satisfaction while summarising the interaction of construction, stability and explanation functions. The function is named with full precomputation because all frameworks are fully constructed before explanations.

\subsection{Memory Limitations}

A full framework requires at least $m^2n^2$ bytes space in memory. For, $m=n=256$ this requires 4GiB. One solution is not to construct frameworks and compute their stability in sequence, but rather inline partial framework construction into frameworks. This reduces the memory complexity to $\mathcal{O}(mn)$, while keeping the same computational complexity. This obviously will be slower to compute, but this method is more scalable. Therefore, we need to modify any function requiring a data object of size $m^2n^2$ such as $\mathbf{c}$ and $\mathbf{x}$.
\linespace
The framework construction functions are trivially modified to compute a sub-graph from a node, given its indices. For example, $\textsc{Construct-Feasibility}(i,j)=\rightsquigarrow_{F_{i,j}}$

\begin{algorithm}[H]
	\caption{}
	\begin{algorithmic}[1]
		\Function{Partial-Precomputation-Explain}{$m$, $n$, $\mathbf{p}$, $D$, $\mathbf{x}$}
			\Function{$\rightsquigarrow'_F$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Feasibility}($m$, $n$, $i$, $j$)
			\EndFunction
			\Function{$\mathbf{c'_F}$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Conflicts}($\mathbf{x}$, $\rightsquigarrow'_F$, $\mathbf{0}$)
			\EndFunction
			\Function{$\rightsquigarrow'_S$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Efficiency}($m$, $n$, $\mathbf{p}$, $\mathbf{x}$, $D$, $i$, $j$)
			\EndFunction
			\Function{$\mathbf{c'_S}$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Conflicts}($\mathbf{x}$, $\rightsquigarrow'_S$, $\rightsquigarrow'_F$)
			\EndFunction
			\Function{$\rightsquigarrow'_D$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Satisfaction}($m$, $n$, $D$, $i$, $j$)
			\EndFunction
			\Function{$\mathbf{c'_D}$}{$i$, $j$}
				\State \Return \textsc{Construct-Partial-Conflicts}($\mathbf{x}$, $\rightsquigarrow'_D$, $\rightsquigarrow'_F$)
			\EndFunction
			\State $\mathbf{u_F}$ $\gets$ \textsc{Computed-Unattacked}($\mathbf{x}$, $\rightsquigarrow'_F$, $\mathbf{0}$)
			\State \textsc{Explain-Feasibility}($\mathbf{u_F}$, $\mathbf{c'_F}$)
			\State $\mathbf{u_S}$ $\gets$ \textsc{Computed-Unattacked}($\mathbf{x}$, $\rightsquigarrow'_S$, $\mathbf{u_F}$)
			\State \textsc{Explain-Efficiency}($\mathbf{u_S}$, $\mathbf{c'_S}$)
			\State $\mathbf{u_D}$ $\gets$ \textsc{Computed-Unattacked}($\mathbf{x}$, $\rightsquigarrow'_D$, $\mathbf{u_F}$)
			\State \textsc{Explain-Satisfaction}($\mathbf{u_D}$, $\mathbf{c'_D}$)
		\EndFunction
	\end{algorithmic}
\end{algorithm}

%    feasibility_unattacked = compute_unattacked(S, ff_partial, None, False)
%    explanations.append(format_argument('Schedule is {}feasible',
%        explain_feasibility(feasibility_unattacked, fc_partial, False)))

%    efficiency_unattacked = compute_unattacked(S, ef_partial,
%        feasibility_unattacked, False)
%    explanations.append(format_argument('Schedule is {}efficient',
%        explain_efficiency(p, S, C, C_max, efficiency_unattacked, ec_partial, False)))

%    satisfaction_unattacked = compute_unattacked(S, df_partial,
%        feasibility_unattacked, False)
%    explanations.append(format_argument('Schedule does {}satisfies user fixed decisions',
%        explain_satisfaction(nfd, pfd, satisfaction_unattacked, dc_partial, False)))


