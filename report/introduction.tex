\chapter{Introduction}
	
\section{Motivation}

Scheduling arises in countless decision processes and its abstract nature results in a wide range of practical applications, such as in healthcare \cite{sanr,operations}. Scheduling problems are accurately modelled in mathematics, hence scheduling is often interpreted as a class of mathematical optimisation problems. With many mature and developed optimisation solvers \cite{clp}, they can find solutions to large scheduling problems quickly, which are impractical using manual optimisation techniques. However, solver scalability and performance considerations often lead to complex algorithms. This combined with mathematical formulations of scheduling, result in users interpreting solvers and solutions as black boxes. Therefore, decision-making is often not transparent.
\linespace
Transparency of decision making is important. Users require to understand why a particular schedule is reasonable. For example, hospital managers may seek to understand the efficiency of their staff. Schedules may need to be robust to unpredictable changes in staff and resources, such as a nurse being unavailable to attend patients. In other scenarios, schedules may need to minimise staff to maximise profits while fulfilling all staff and patient requirements.
\linespace
Explanations are vital in communication for understanding. With many possible schedules and many variations of scheduling problems \cite{sta}, it is impractical to manually-craft explanations for every schedule of every variation. This motivates a tool to generate clear explanations.

\section{Objectives}
\label{objectives}

The first objective is to devise and implement an interactive tool that explains solvers' solutions so that schedules are human-understandable. We implement the explanation methodology outlined in the paper \cite{aes}. With argumentation, the user can easily understand scheduling in a practical environments such as nurse rostering and dialysis scheduling. The analysis of such methodology is important to understand the applicability of argumentation in practical settings.
\linespace
The second objective is to extend the theoretical and practical capabilities of argumentation for scheduling. Extensions may include interval scheduling, shop scheduling and job-dependent scheduling.

\section{Challenges}
\label{challenges}

A tool satisfying these objectives must meet the following challenges:
\begin{enumerate}
	\item\textbf{Trust:} Users of the tool need to be confident that the explanations generated are true. That is, the algorithms proposed and implemented are correct.
	\item\textbf{Accessibility:} Explanations generated from this tool are required to be accessible to computer novices without domain-specific knowledge of optimisation or argumentation.
	\item\textbf{Applicability:} Explanations should relate to makespan schedules. The tool should generate clear explanations promptly to users.
	\item\textbf{Knowledge transfer:} Explanations are constructed using knowledge structures, commonly represented using natural languages or diagrams. A challenge would be to effectively explore the usefulness of using natural languages compared to diagrams.
	\item\textbf{Background:} Explainable planning is relatively new research area compared to optimisation \cite{pe}. Challenges arise from finding related literature on the project area.
\end{enumerate}

\section{Contributions}
\label{introcontributions}

The main contributions of this project are listed as follows:
\begin{itemize}
	\item A new tool \emph{\toolname} that implements the concepts behind using argumentation for makespan scheduling. (Appendix \ref{userguide})
	\item Algorithms and their optimisations, alongside with proofs as necessary. (Chapter \ref{implementation})
	\item Theoretical applications of argumentation with theorems. (Chapter \ref{properties})
	\item A discussion on applicability of argumentation. (Chapter \ref{conclusion})
\end{itemize}
