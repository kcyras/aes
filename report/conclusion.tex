\chapter{Conclusion}
\label{conclusion}

\section{Contributions}
We restate our contributions from Section \ref{introcontributions}.

\begin{itemize}
	\item We implement a new tool \emph{\toolname}, as in Chapter \ref{implementation}.
	\item We define algorithms that balances between computational complexity and explanation expressibility.
	\item We give theoretical applications of argumentation with Theorem \ref{modelling} and \ref{intervalfeasibilty}, which shows that argumentation frameworks can be overlapped to aggregate schedule properties.
	\item A discussion on the applicability of argumentation, as discussed in this chapter.
\end{itemize}

\section{Limitations of Argumentation}

We show that argumentation can interface between optimisation solvers and explanation generators. By computing the satisfaction of extensions, such as stability, solvers are exposed as white-box algorithms, transforming argumentation semantics into human-understandable explanations. However, this application of argumentation is flawed in practice. 

\begin{itemize}
	\item\textbf{Memory performance:} Abstract argumentation operates on directed graphs, whose data structure storage suffers from quadratic space complexity. Using the direct implementation of the paper \cite{aes}, namely, the full-precomputation approach, at 256 machines and jobs, each framework requires 4GiB of memory. To solve this scalability issue, the tool instead operates on partitioned directed graphs, resulting in optimal linear space complexity. However, optimal complexity does not yield optimal performance, because at best, the partial-precomputation approach uses the same amount of memory as the non-argumentative approach, as shown by our empirical results.
	\item\textbf{Computational performance:} In order for argumentation semantics to correspond to schedule properties, extensions must be global to capture the space of the problem's linear constraints. Local extensions such as conflict-freeness and admissibility are insufficient to model makespan schedules. Hence, we use the stability extension, which suffers from quadratic computational complexity. This is inefficient compared to a non-argumentative approach, where makespan feasibility can be computed in linear complexity. Therefore, any argumentation approach regarding to makespan scheduling is less scalable than an non-argumentative approach.
	\item\textbf{Abstracted interface:} For argumentation to be exploited as a white-box, users should interact with the underlying argumentation. This is possible for small schedules where the number of machines, jobs and their attacks are limited. But for realistic schedule sizes of at least tens of machines and jobs, argumentation frameworks become too busy to be visualised clearly. As such, users will abstract the argumentative interface of the tool as a black box, so users may ignore the underlying argumentation semantics.
	\item\textbf{Functionality equivalence:} In a black box comparison of an argumentative approach versus a non-argumentative approach, both result in identical explanations given identical problems and schedules. This is verified with the tool by comparing results with and without the \texttt{--naive} flag over extensive test cases. In a practical setting, users will favour using the non-argumentative approach for general performance.
	\item\textbf{Implementation complexity: }The optimisation of the algorithms used in argumentative approaches results in more complex source-code. This is highlighted that the argumentative approaches are written in over approximately 300 lines of Python while the non-argumentative approach is written within 100 lines. In conjunction with the above functional equivalence statement, we can interpret the non-argumentative approach as a refactoring of the argumentative approaches.
\end{itemize}

While argumentation offers, soundness, completeness, polynomial tractability and polynomial computational complexity, a non-argumentative approach remains sufficiently viable.

\section{Practicability of Argumentation}
\label{practicability}

Without knowledge of argumentation, one could define mappings between mathematical constraints and templated-explanations to create an interactive tool. We argue that argumentation is unnecessary in the development process. However, argumentation may bring subtle benefits that are not expressible in makespan scheduling.
\linespace
Argumentation brings an alternative representation of conflicts or constraints. This representation is competitive in recommender systems \cite{recommend}, where chains of reasons can be constructed. In abstract argumentation, chain of reasons are constructed when a extension is fixed-point computable. This is true with admissible and complete extensions. However, with stability and conflict-freeness, as in our algorithms, the counter-arguments for a stable or a conflict-free extension does not construct chains of arguments. A potential solution to improve explanations, is to verify that mathematical constraints are admissible-modellable. However, at the time of writing, the notion of admissible and linear constraints have little connection. 
\linespace
We have shown in Chapter \ref{properties} that is it possible to translate new constraints to new frameworks. Each constraint and their explanations are loosely-coupled by an AAF. We have attempted to link efficiency and fixed user decisions by defining fixed-decision aware exchange properties. This link was inspired by intuitive interpretation of the problem. More generally, schedules can be subject to multi-objective optimisation. If we consider conflicts between objectives, rather than conflicts between possible schedules under a mathematical constraint, then we can use argumentation to compromise between objectives. We can infer an explanation from the chain of arguments. However, the maximum chain of arguments is restricted to the number of schedule properties. Given we have only three properties in makespan scheduling, these explanations do not offer much beyond a simple inspection of a schedule.

\begin{figure}[H]
	\label{problempath}
	\input{problempath}
	\caption{Venn diagram of makespan schedule properties with a local schedule optimisation path. Red arrows represent a schedule becoming unsatisfied of some property.}
\end{figure}

As illustrated in Figure \ref{problempath}, our tool can take a schedule, possibly empty, and iteratively improve on it. However, at certain intermediate schedules, we may not improve the schedule in trivial ways to satisfy schedule properties, possibly because of nurse preferences. This results in steps which contradict already-satisfied properties, as highlighted in red. Given an explanation constructed using argumentation, we can justify the compromise between schedule properties using preferences.

\begin{figure}[H]
	\label{problemspace}
	\input{problemspace}
	\caption{Complete makespan problem space for $m=n=2$, $\mathbf{p}=[1,1]$, $D^-=\{\pair{2}{1}\}$ and $D^+=\varnothing$. The shaded schedule satisfies all properties.}
\end{figure}

It is possible that all possible improvements on a schedule may contradict already-satisfied properties. Consider figure \ref{problemspace}, where we give a concrete problem. At schedule $[[0\ 0]\ [0\ 1]]$, all improvements are marked as red. Suppose we have no preferences on schedules. In this case, we cannot justify making any improvements because we enforce all schedule properties to hold. There are better schedules, but they are inaccessible given our current schedule. In other words, we have reached a local optimum using explanations. This motivates to use global search, but as we stated before, this in intractable for arbitrary schedule spaces. Therefore, there is a clear trade-off between expressibility and computational tractability of explanations. Given the scope of this project, there is no conclusive method to tractably compute complete generalised explanations.

\section{Discussion of Objectives}

We complete the first objective (stated in section \ref{objectives}), that is to implement a tool satisfying the challenges mentioned (section \ref{challenges}). We revisit these challenges as follows:
\begin{enumerate}
	\item\textbf{Trust:} We use both formal and practical verification methods to ensure our program is correct. We give proofs to our algorithms (section \ref{stabilityproof}) and a test framework (section \ref{testability}).
	\item\textbf{Accessibility:} From our survey, we have shown users can construct and manipulate problems and schedules to model scenarios.
	\item\textbf{Applicability:} From our survey, we have shown users can use explanations to aid decision-making.
	\item\textbf{Knowledge transfer:} In the tool, we provide both a cascade chart alongside an interactive explanation. The feedback from users suggested that explanations were relatively clear given a diagram. The extent in which the interface provides the best knowledge transfer is not known.
	\item\textbf{Background:} We have been able to construct a functional tool with limited implementation details from the paper \cite{aes}.
\end{enumerate}

From the survey, we have shown that explanations allows better reasoning of makespan schedules. The survey responses suggests that the tool is better suited to comparing and understanding different scheduling cases, than understanding how to optimise a schedule. This contradicts the original premise where optimisation of a particular schedule is the focus. Given we implement the tool with focus on polynomial algorithms, it is difficult to interface users with clear explanations for optimality or near-optimality of schedules. This implies that the tool would be better suited to comparing schedules. As this is a form of replanning, the tool is useful in decision-maker, but lacks expressibility for general replanning.
\linespace
We make progress the second objective, that is to extend theoretical or practical capabilities of argumentation for scheduling. This is evident from Chapter \ref{properties}. From section \ref{practicability}, we have shown further effort is challenging. The future of using argumentation for scheduling is unknown at the time of writing and future work may transform the paradigm first mentioned in the paper \cite{aes} into a disruptive technology.

\section{Future Work}

\begin{itemize}
	\item\textbf{Space of stability-modellable linear programs:} We have shown that makespan and interval scheduling are stability-modellable. An interesting direction would be to explore the space of linear programming problems that are stability-modellable, or more generally, extension-modellable. This is particularly difficult because of limitations with local extensions and non-polynomial verification \cite{aes}.
	\item\textbf{Implementation of interval scheduling:} We have shown that interval scheduling feasibility is stability-modellable. Due to the time constraints of this project, we have not been able to integrate makespan and interval scheduling into a single graphical tool.
	\item\textbf{Preferences:} It is known that previous literature ignores machines or job preferences, or attempts to simplify individual preferences as groups \cite{preferences}. A future direction would be to explore the modelling preferences using existing argumentation methods \cite{acceptability, aba} with a focus on explanations.
	\item\textbf{Web GUI:} The Python GUI is clear for users from an academic environment. But in comparison with commercial tools, their interface allows users to reschedule by intuitive drag-drop interactions. This was beyond the scope of an academic project.
\end{itemize}

\section{Summary}

\begin{framed}
	\centering
	Explaining makespan schedules using argumentation is\\practically
	possible but not practically suitable.
\end{framed}