\chapter{Conclusion}

\section{Limitations}

Argumentation interfaces between optimisation solvers and explanation generators. By computing satisfaction of extensions, such as stability, solvers are exposed as white-box algorithms, transforming argumentation semantics into human-understandable explanations. However, this application of argumentation is flawed in practice. 

\begin{itemize}
	\item\textbf{Memory performance:} Abstract argumentation operates on directed graphs, whose data structure storage suffers from quadratic space complexity. Using the direct implementation of the paper \cite{aes}, namely, the full-precomputation approach, at 256 machines and jobs, each framework requires 4GiB of memory. To solve this scalability issue, the tool instead operates on partitioned directed graphs, resulting in optimal linear space complexity. However, optimal complexity does not yield optimal results, as at best, the partial-precomputation approach uses at least same amount of memory as the non-argumentative approach, from our empirical results.
	\item\textbf{Computational performance:} In order for argumentation semantics to correspond to schedule properties, such as feasibility, extensions must be global to capture the space of the problem's linear constraints. Local extensions such as conflict-freeness and admissibility are insufficient to model makespan schedules. Hence, we use the stability extension, which has quadratic computational complexity. This is inefficient compared to an non-argumentative approach, where makespan feasibility can be computed in linear complexity. Therefore, any argumentation approach is less scalable than an non-argumentative approach.
	\item\textbf{Abstracted interface:} For argumentation to be exploited as a white-box, users should interact with the underlying argumentation. This is possible for small schedules where the number of machine job pairs and their attacks are limited. But for realistic schedule sizes of at least tens of machines and jobs, argumentation frameworks become too busy to be visualised clearly. As such, the argumentative interface of the tool is abstracted, as a black-box, where users of the tool may ignore the underlying argumentation semantics.
	\item\textbf{Functionality equivalence:} In a black-box comparison of an argumentative versus a non-argumentative approach, both approaches result in identical explanations given identical problems and schedules. This is verified with the tool by comparing results with and without the \texttt{--naive} flag over many test cases. In practical settings, users will favour using the non-argumentative approach for CPU and memory performance.
	\item\textbf{Implementation complexity: }To optimise the performance computational and memory of argumentative approaches, the source-code becomes more difficult to understand. This is highlighted that the argumentative approaches are written in approximately 300 lines of Python while the non-argumentative approach is written in 100 lines. In conjunction with the above functional equivalence statement, we can interpret the non-argumentative approach as a refactoring of the argumentative approaches.
\end{itemize}

While argumentation offers, soundness, completeness, polynomial tractable and computational complexity, a non-argumentative approach can offer these too.

\section{Discussion}

Without knowledge of argumentation, one could define mappings between mathematical constraints and templated-explanations to create an interactive tool. We argue that argumentation was not necessary in the development process. However, argumentation brings subtle benefits that are not expressible in makespan scheduling.
\linespace
Argumentation brings an alternative representation of conflicts or constraints. This representation is competitive in recommender systems \cite{recommend}, where chain of reasons are constructed. In abstract argumentation, chain of reasons are constructed when an extension depth-recursively effects satisfaction. This is true with admissible and complete extensions. However, with stability and conflict-freeness, as used in our algorithms, the counter-arguments for a stable or a conflict-free extension does not recurse on the AAF. A potential solution to make better explanations, is to verify that mathematical constraints are admissible-modellable. However, at the time of writing, the notion of admissible and linear constraints have little connection. 
\linespace
We have shown in Chapter \ref{properties} that is it possible to translate new constraints to new frameworks. Each constraint and their explanations are loosely-coupled by an AAF. We have attempted to link efficiency and fixed user decisions by defining fixed-decision aware exchange properties. However, this link was inspired by intuitive interpretation of the problem. More generally, schedules can be subject to multi-objective optimisation. If we consider conflicts between objectives, rather than conflicts between possible schedules under a mathematical constraint, then we use can argumentation to compromise between objectives. By computing admissibility, we can infer an explanation from the chain of conflicting arguments. However, the depth of the explanation is restricted to the number of schedule properties. Given we have only three properties, these explanations do not offer much beyond a simple inspection of a schedule.

\begin{figure}
	\label{problempath}
	\input{problempath}
	\caption{Venn diagram of makespan schedule properties with a local schedule optimisation path. Red arrows represent a schedule becoming unsatisfied of some property.}
\end{figure}



\begin{figure}
	\label{problemspace}
	\input{problemspace}
	\caption{Complete makespan problem space for $m=n=2$, $\mathbf{p}=[1,1]$, $D^-=\{\pair{2}{1}\}$ and $D^+=\varnothing$. The shaded schedule is satisfies all properties.}
\end{figure}

As illustrated in Figure \ref{problempath}, our tool can take a schedule, possibly an empty schedule, and iteratively improve on it. However, at certain intermediate schedules, we may not improve the schedule in trivial ways to satisfy schedule properties, possibly because of nurse preferences. This results in steps which contradict already-satisfied properties, as highlighted in red. Given an explanation constructed using argumentation, we can justify the compromise between schedule properties using preferences.
\linespace
It is possible that all possible improvements on a schedule may contradict already-satisfied properties. Consider figure \ref{problemspace}, where we give a concrete problem. At schedule $[[0\ 0]\ [0\ 1]]$, all improvements are marked as red. Suppose we have no preferences on schedules. In this case, we cannot justify making any improvements because we enforce all schedule properties to hold. There are better schedules, but they are inaccessible given our current schedule. In other words, we have reached an local optimal using explanations. This motivates to use global search, but as we stated before, this in intractable for arbitrary schedule spaces. Therefore, there is a clear trade-off between expressibility and computational tractability of explanations. Given the scope of this project, there is no inconclusive method to compute complete generalised explanations.

\section{Future Work}

\begin{itemize}
	\item\textbf{Space of stability-modellable linear programs:} We have shown that makespan and interval scheduling are stability-modellable. An interesting direction would be to explore the space of linear programming problems that are stability-modellable, or more generally, extension-modellable.
	\item\textbf{Implementation of interval scheduling:} We have shown that interval scheduling feasibility is stability-modellable. Due to the time constraints of this project, we have not been able to integrate makespan and interval scheduling into a single graphical tool.
	\item\textbf{Nurse preferences:} It is known that previous literature ignores nurses preferences, or attempts to simplify individual nurses preferences as groups \cite{preferences}. A future direction would be to explore the modelling individual nurses preferences using existing argumentation methods \cite{acceptability, aba}
	\item\textbf{Web GUI:} The Python GUI is clear for users from an academic environment. But in comparison with commercial tools, their interface allows users to reschedule by intuitive drag-drop interactions. This was beyond the scope of an academic project.
\end{itemize}

\section{Summary}

\begin{framed}
	\centering
	Makespan scheduling using argumentation is\\practically
	possible but not practically suitable.
\end{framed}